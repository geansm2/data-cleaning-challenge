{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Cleaning Challenge: Enfrentando o Caos dos Dados Reais\n",
    "\n",
    "## 1. O Problema\n",
    "Muitos datasets acadêmicos são entregues \"limpos\". Na vida real, os dados chegam incompletos, com formatos inconsistentes, duplicados e erros humanos. \n",
    "\n",
    "Este projeto demonstra minhas habilidades em **Data Wrangling** e **Data Cleaning**, transformando um CSV caótico em uma base de dados pronta para análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diagnóstico da Sujeira\n",
    "Ao carregar o dataset `vendas_brutas_caos.csv`, identificamos os seguintes problemas:\n",
    "- **Inconsistência de Texto:** Nomes em maiúsculas, minúsculas, com espaços extras e caracteres especiais.\n",
    "- **Formatos de Data:** Mistura de padrões ISO, brasileiro e erros de digitação (mês 13).\n",
    "- **Valores Numéricos:** Moeda (R$), separadores de milhar (.), decimais (,) e valores negativos sem sentido.\n",
    "- **Duplicações:** IDs de transação repetidos com informações conflitantes.\n",
    "- **Missing Values:** Lacunas críticas em colunas de valor e data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Carregando o caos\n",
    "df = pd.read_csv('vendas_brutas_caos.csv', encoding='latin-1')\n",
    "print(\"Amostra dos dados sujos:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plano de Higienização (Data Wrangling)\n",
    "\n",
    "### 3.1 Tratamento de Nomes e Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(name):\n",
    "    if pd.isna(name): return \"Desconhecido\"\n",
    "    name = str(name).strip().upper() # Padronizar para maiúsculo sem espaços nas bordas\n",
    "    name = re.sub(' +', ' ', name)   # Remover espaços múltiplos internos\n",
    "    name = name.replace('_', ' ')     # Corrigir separadores\n",
    "    return name\n",
    "\n",
    "df['cliente_nome'] = df['cliente_nome'].apply(clean_names)\n",
    "df['status'] = df['status'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Padronização de Valores Monetários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency(value):\n",
    "    if pd.isna(value) or value == 'NULL': return 0.0\n",
    "    v = str(value).replace('R$', '').replace(' ', '')\n",
    "    \n",
    "    # Lógica para tratar separador de milhar vs decimal\n",
    "    if ',' in v and '.' in v:\n",
    "        v = v.replace('.', '').replace(',', '.')\n",
    "    elif ',' in v:\n",
    "        v = v.replace(',', '.')\n",
    "        \n",
    "    v_num = pd.to_numeric(v, errors='coerce')\n",
    "    return abs(v_num) if v_num else 0.0 # Trade-off: assumimos valor absoluto para erros de sinal\n",
    "\n",
    "df['valor_venda'] = df['valor_venda'].apply(clean_currency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Conserto de Datas e Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para datetime forçando NaT para erros (como mês 13)\n",
    "df['data_venda'] = pd.to_datetime(df['data_venda'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Preencher datas nulas com a data anterior (forward fill) como política de negócio\n",
    "df['data_venda'] = df['data_venda'].ffill()\n",
    "\n",
    "# Remover duplicados de ID mantendo a última ocorrência (supostamente a mais atualizada)\n",
    "df = df.drop_duplicates(subset='transacao_id', keep='last')\n",
    "\n",
    "print(\"Dados Higienizados:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusão e Trade-offs\n",
    "\n",
    "Neste projeto, tomei as seguintes decisões técnicas:\n",
    "1. **Nomes:** Optei por converter para Maiúsculas para facilitar joins futuros, mesmo perdendo a capitalização original.\n",
    "2. **Valores Negativos:** Usei a função `abs()` assumindo que foram erros de entrada de dados (sinal invertido).\n",
    "3. **Datas Inválidas:** Usei Forward Fill (`ffill`). Em um cenário real, isso dependeria de validar com o time de banco de dados, mas aqui serviu para manter a continuidade da série temporal.\n",
    "\n",
    "**Resultado:** O dataset agora está 100% tipado e consistente para análises estatísticas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}